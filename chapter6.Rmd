---
output: html_document
---
# Analysis of longitudinal data
## Data description 
For this week assignment I use two datasets:

1. BPRS - Brief Psychiatric Rating Scale Measurements from 40 Subjects
2. RATS - Body Weights of Rats Recorded Over a 9-Week Period


## Chapter 8 of MABS using the RATS 

```{r}
library(tidyr)
library(dplyr)
library(ggplot2)

RATS <- read.table("https://raw.githubusercontent.com/KimmoVehkalahti/MABS/master/Examples/data/rats.txt", 
                   sep  ="", header = T)
RATS$ID <- factor(RATS$ID)
RATS$Group <- factor(RATS$Group)
RATSL <- read.csv("~/IODS-project/data/RATSL.csv")
RATSL$ID <- factor(RATSL$ID)
RATSL$Group <- factor(RATSL$Group)
```
First, let's plot the RATS values for all 16 rats, differentiating between the study groups.The weight of almost all the rats is increasing over the research period. The animals that have higher weight values at the beginning tend to have higher values throughout the study. There are also substantial differences between rats. 
```{r}
p1 <- ggplot(RATSL, aes(x = time, y = rats, color = ID))
p2 <- p1 + geom_line() + scale_linetype_manual(values = rep(1:10, times=4))
p3 <- p2 + facet_grid(. ~ Group, labeller = label_both)
p4 <- p3 + theme_bw() + theme(legend.position = "none")
p5 <- p4 + theme(panel.grid.minor.y = element_blank())
p6 <- p5 + scale_y_continuous(limits = c(min(RATSL$rats), max(RATSL$rats)))
p6
```

Let's scale the data by subtracting the mean from the original observation and then dividing by the corresponding standard deviation. 
```{r}
# Standardise the scores:
RATSL <- RATSL %>%
  group_by(time) %>%
  mutate(stdrats = (rats - mean(rats))/sd(rats) ) %>%
  ungroup()
glimpse(RATSL)
```

Now I plot scaled data separated by group again.

```{r}
p1 <- ggplot(RATSL, aes(x = time, y = stdrats, color = ID))
p2 <- p1 + geom_line() + scale_linetype_manual(values = rep(1:10, times=4))
p3 <- p2 + facet_grid(. ~ Group, labeller = label_both)
p4 <- p3 + theme_bw() + theme(legend.position = "none")
p5 <- p4 + theme(panel.grid.minor.y = element_blank())
p6 <- p5 + scale_y_continuous(name = "standardized rats")
p6
```

The mean profiles of the three groups suggest that there is a big difference between them with respect to the mean weight values.
 
```{r}
# Number of times, baseline (time 1) included:
n <- RATSL$time %>% unique() %>% length()
```

Now we will analyze the summary dataset. 
```{r}
# Make a summary data:
RATSS <- RATSL %>%
  group_by(Group, time) %>%
  summarise(mean=mean(rats), se=sd(rats)/sqrt(n) ) %>%
  ungroup()
glimpse(RATSS)
```

The following graph shows the average profile for each study group along with some indication of the variation of the observations at each time point. There is no overlap in the mean profiles of the three groups, meaning there is a significant difference between them with respect to the mean weight values.

```{r}
p1 <- ggplot(RATSS, aes(x = time, y = mean, color = Group, shape = Group))
p2 <- p1 + geom_line() + scale_linetype_manual(values = c(1,2,3))
p3 <- p2 + geom_point(size=3) + scale_shape_manual(values = c(1,2,3))
p4 <- p3 + geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=0.3)
p5 <- p4 + theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
p6 <- p5 + scale_y_continuous(name = "mean(rats) +/- se(rats)")
p6
```

We can also investigate the mean profiles with box plots of the observations at each time point. The plot suggests the presence of some possible “outliers” at most time points and indicates again the general increase in weight values over the nine weeks of the study in all the groups.

```{r}
p1 <- ggplot(RATSL, aes(x = factor(time), y = rats, fill = Group))
p2 <- p1 + geom_boxplot(position = position_dodge(width = 0.9))
p3 <- p2 + theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
p4 <- p3 + scale_x_discrete(name = "time")
p4
```

```{r}
RATS11S <- RATSL %>%
  filter(time > 1) %>%
  group_by(Group, ID) %>%
  summarise(mean=mean(rats) ) %>%
  ungroup()
glimpse(RATS11S)
```

Now we will implement the summary measure approach. The mean of weeks 1 to 9 will be the chosen summary measure. We first calculate this measure and then look at box plots of the measure for each study group. 

```{r}
p1 <- ggplot(RATS11S, aes(x = Group, y = mean))
p2 <- p1 + geom_boxplot()
p3 <- p2 + theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
p4 <- p3 + stat_summary(fun.y = "mean", geom = "point", shape=23, size=4, fill = "thistle")
p5 <- p4 + scale_y_continuous(name = "mean(rats), times 2-64")
p5
```

There are outliers in each group, however the box plot of the second group is most severely skewed by it. So, we shall remove an observation where mean RATS score is over 550. 

```{r}
RATS11S1 <- RATS11S %>%
  filter(mean < 550)
glimpse(RATS11S1)
```

```{r}
p1 <- ggplot(RATS11S1, aes(x = Group, y = mean))
p2 <- p1 + geom_boxplot()
p3 <- p2 + theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
p4 <- p3 + stat_summary(fun.y = "mean", geom = "point", shape=23, size=4, fill = "thistle")
p5 <- p4 + scale_y_continuous(name = "mean(rats), times 2-64")
p5
```

Although the mean difference is quite obvious from the graph, we can formally test for it implementing analysis of variance (ANOVA).
```{r}
# ANOVA instead of two-sided t-test
summary(aov(mean ~ Group, data = RATS11S1))
```
P-value is close to zero, which suggests that differences are significant indeed. But we still don't know between which groups exactly. So, I will subset the dataset and compare groups separately. 
```{r}
RATS11S1gr12 <- RATS11S1[which(RATS11S1$Group =='1' | RATS11S1$Group =='2'), ]
t.test(mean ~ Group, data = RATS11S1gr12, var.equal = TRUE)
```
**The difference between means in Group 1 and Group 2 is highly significant**. 

```{r}
RATS11S1gr13 <- RATS11S1[which(RATS11S1$Group =='1' | RATS11S1$Group =='3'), ]
t.test(mean ~ Group, data = RATS11S1gr13, var.equal = TRUE)
```
**The difference between means in Group 1 and Group 3 is highly significant**. 

```{r}
RATS11S1gr23 <- RATS11S1[which(RATS11S1$Group =='2' | RATS11S1$Group =='3'), ]
t.test(mean ~ Group, data = RATS11S1gr23, var.equal = TRUE)
```
**The difference between means in Group 2 and Group 3 is significant**. 

Baseline measurements of the outcome variable in a longitudinal study are often correlated with the chosen summary measure and can boost our precision score in an analysis of covariance. We will use the RATS value corresponding to the first week period as the baseline covariate. 


```{r}
# Add the baseline from the original data as a new variable to the summary data:
baseline <- RATS$WD1
RATS11S2 <- RATS11S %>%
  mutate(baseline)
```

```{r}
# Fit the ANCOVA model and see the results:
fit <- lm(mean ~ baseline + Group, data = RATS11S2)
summary(fit)
anova(fit)
```
We see that the baseline RATS is strongly related to the RATS values taken after experiment has begun (baseline is highly covariated with the mean). It is also covarited with Group, which proves one more time that mean really depends on study group. 

## Chapter 9 of MABS using the BPRS
```{r}
BPRS <- read.table("https://raw.githubusercontent.com/KimmoVehkalahti/MABS/master/Examples/data/BPRS.txt", 
                   sep  =" ", header = T)
# subject numbers in different treatment groups are similar
# so both groups have subject #1, subject #2 etc
# we have to change it, since those are different individuals actually
BPRS$subject <- seq(1, 40)
BPRS$treatment <- factor(BPRS$treatment)
BPRS$subject <- factor(BPRS$subject)
BPRSL <-  BPRS %>% gather(key = weeks, value = bprs, -treatment, -subject)
BPRSL$treatment <- factor(BPRSL$treatment)
BPRSL$subject <- factor(BPRSL$subject)
BPRSL <-  BPRSL %>% mutate(week = as.integer(substr(weeks,5, 5)))
```

```{r}
p1 <- ggplot(BPRSL, aes(x = week, y = bprs, group = subject))
p2 <- p1 + geom_text(aes(label = treatment))
p3 <- p2 + scale_x_continuous(name = "week", breaks = seq(0, 60, 10))
p4 <- p3 + scale_y_continuous(name = "bprs")
p5 <- p4 + theme_bw()
p6 <- p5 + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
p6
```

It's hard to make any specific inferences from this chart. Let's move forward and represent the data with a line graph. First all, the observations in both groups tend to decrease over the treatment period. The variance in the second treatment group seems to be higher than in the first one. However, there is no an obvious difference between the BPRS of men in the group 1 and in the group 2.
```{r}
p1 <- ggplot(BPRSL, aes(x = week, y = bprs, group = subject))
p2 <- p1 + geom_line(aes(color = treatment))
p3 <- p2 + scale_x_continuous(name = "Week", breaks = seq(0, 8, 2))
p4 <- p3 + scale_y_continuous(name = "BPRS")
p5 <- p4 + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
p5
```

In further analysis we will try to fit linear models to our data.
To begin, we assume that all the observations are independent of one another and fit a **multiple linear regression model** with BPRS as response and week and treatment as explanatory variables. 
```{r}
BPRS_reg <- lm(bprs~week+treatment, data=BPRSL)
summary(BPRS_reg)
```
We can now see that 'week' is significant, but treatment is not. As we could expect, group 1 and group 2 do not differ significantly from each other conditional on time.

As we can see from the pairs graph there is a clear relationship between BPRS values and time (week).

```{r}
pairs(BPRS[, 3:11], cex = 0.7)
```

Let's now fit the **random intercept model** for the same two explanatory variables so that we have different intercepts for different subjects. Vertical bars (|) stand for the random-effects terms. And the theoretical model representation looks as follows:$y_{i, j} = (\beta_0 + u_i) + \beta_1 t_j + \epsilon_{i,j}$. In our case it takes form of $bprs_{i, j} = (\beta_0 + u_i) + \beta_1 week_j + \beta_2 treatment_{i,1} + \epsilon_{i,j}$, where $u_i$ is the random effect specific to the $i$th subject.
```{r}
library("lme4")
BPRS_ref <- lmer(bprs ~ week + treatment + (1 | subject), data = BPRSL, REML = FALSE)
summary(BPRS_ref)
```
The estimated variance of the random effects is huge (2572,9), indicating the considerable variation in the intercepts of the regression fits of the individual profiles. The estimated coefficient for 'week' didn't change, but the coefficient for 'treatment' changed a lot, although it's still not significant. The standard deviation for 'week' variable decreased comparing to a multivariate linear regression model. In contrast, the standard error of a treatment dummy variable is more than twice higher. 

Now let's fit the **random slope model** to the BPRS dataset. And the theoretical model representation looks as follows:$y_{i, j} = (\beta_0 + u_i) + (\beta_1 +v_i) t_j + \epsilon_{i,j}$. In our case: $bprs_{i, j} = (\beta_0 + u_i) + (\beta_1 +v_i) week_j + \beta_2 treatment_{i, 1} + \epsilon_{i,j}$. This model allows the linear regression fits for each individual to differ in slope.

```{r}
BPRS_ref1 <- lmer(bprs ~ week + treatment + (week | subject), data = BPRSL, REML = FALSE)
summary(BPRS_ref1)
```
The coefficient for a treatment dummy variable tripled. The likelihood ratio for the random intercept model versus the random intercept and slope model is smaller, which indicates that the model better suits the data. 

```{r}
anova(BPRS_ref1, BPRS_ref)
```

Finally, let's try to add an interaction term week*treatment. Explicitly, this model can be written as: $bprs_{i, j} = (\beta_0 + u_i) + (\beta_1 +v_i) week_j + \beta_2 treatment_{i, 1} + \beta_3(week_j \times treatment_{1,i})  + \epsilon_{i,j}$.
```{r}
BPRS_ref2 <- lmer(bprs ~ week * treatment + (week | subject), data = BPRSL, REML = FALSE)
summary(BPRS_ref2)
```
According to the likelihood ratio the latter model is the best. Although, neither the treatment dummy nor the intersection term are significant. The estimated regression parameters for the interaction indicate that the bprs slopes are higher for men in group 2 than for men in group 1.

```{r}
anova(BPRS_ref1, BPRS_ref2)
```
From the ANOVA results above we can see that p-value is not small enough to prove that the random intercept and slope model provides a better fit for these data though.

We can find the fitted values from the interaction model and plot the fitted BPRS for each subject.

```{r}
Fitted <- fitted(BPRS_ref2)
BPRSL <- BPRSL %>% mutate(Fitted)
```

It can be seen that the fitted lines are far smoother than the observed ones. This graphic underlines that the interaction model doesn't really fits the observed data well.
```{r}
p1 <- ggplot(BPRSL, aes(x = week, y = bprs, group = subject))
p2 <- p1 + geom_line(aes(color = treatment))
p3 <- p2 + scale_x_continuous(name = "Week", breaks = seq(0, 8, 2))
p4 <- p3 + scale_y_continuous(name = "BPRS")
p5 <- p4 + theme_bw() + theme(legend.position = "right") # "none" in the book
p6 <- p5 + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
p7 <- p6 + ggtitle("Observed")
graph1 <- p7
```

```{r}
p1 <- ggplot(BPRSL, aes(x = week, y = Fitted, group = subject))
p2 <- p1 + geom_line(aes(color = treatment))
p3 <- p2 + scale_x_continuous(name = "Week", breaks = seq(0, 8, 2))
p4 <- p3 + scale_y_continuous(name = "BPRS")
p5 <- p4 + theme_bw() + theme(legend.position = "right")
p6 <- p5 + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
p7 <- p6 + ggtitle("Fitted")
graph2 <- p7
```

```{r}
graph1; graph2
```

**That's the end!**
```{r, echo=FALSE}
knitr::asis_output("\U1F973 \U1F929   \U1F389")
```














